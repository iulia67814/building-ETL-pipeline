## ETL PIPELINE

This repository contains my first try of building an ETL pipeline.

Extract, transform, and load (ETL) is the process of combining data from multiple sources into a large, central repository called a data warehouse. 
ETL uses a set of business rules to clean and organize raw data and prepare it for storage, data analytics, and machine learning (ML).

In the given example I've extracted data from Redshift, explored it and made some cleaning of data i.e. transformation and then loaded it to an AWS S3 bucket.